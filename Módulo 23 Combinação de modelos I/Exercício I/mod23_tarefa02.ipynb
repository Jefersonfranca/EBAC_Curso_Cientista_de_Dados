{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarefa 02 Módulo 23 Combinação de Modelos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1). Monte um passo a passo para o Random Forest:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processo de Random Forest: Um Passo a Passo\n",
    "\n",
    "#### 1. **Bootstrap com Feature Selection**\n",
    "\n",
    "Para iniciar o processo de Random Forest, primeiro aplicamos o método Bootstrap em conjunto com a seleção de características (Feature Selection). Imagine que você possui um conjunto de dados com várias linhas e colunas. Aplicando o Bootstrap, geramos múltiplos novos conjuntos de dados a partir do original, cada um com o mesmo número de linhas, mas com um subconjunto de colunas. \n",
    "\n",
    "Existem duas fórmulas comuns para decidir quantas colunas serão selecionadas em cada subconjunto:\n",
    "- Para problemas de classificação, o número de colunas é determinado pela raiz quadrada do total de colunas (√p).\n",
    "- Para problemas de regressão, utilizamos um terço do total de colunas (p/3).\n",
    "\n",
    "Após selecionar as colunas, repetimos a amostragem das linhas, permitindo que algumas linhas se repitam e outras sejam excluídas. Continuamos esse processo até gerar o número necessário de novos conjuntos de dados para a nossa análise.\n",
    "\n",
    "#### 2. **Construção da Random Forest**\n",
    "\n",
    "Na etapa de construção da Random Forest, utilizamos os subconjuntos de dados gerados na etapa anterior para treinar várias árvores de decisão. Cada árvore é treinada em um conjunto de dados ligeiramente diferente, o que contribui para a diversidade do modelo. Essa coleção de árvores de decisão forma a chamada \"Floresta Aleatória\" (Random Forest), que é essencial para aumentar a precisão e reduzir o overfitting em comparação com uma única árvore de decisão.\n",
    "\n",
    "#### 3. **Agregação (Bagging)**\n",
    "\n",
    "Finalmente, chegamos à etapa de agregação, conhecida como Bagging (Bootstrap Aggregating). Nessa fase, combinamos os resultados das diferentes árvores de decisão. Para problemas de classificação, coletamos as predições de cada árvore e selecionamos a classe mais votada (1 ou 0) como o resultado final. Em problemas de regressão, calculamos a média das predições das árvores. Esse processo de agregação ajuda a melhorar a robustez e a precisão do modelo, proporcionando uma predição mais confiável e estável.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2). Monte um passo a passo para o Random Forest:\n",
    "\n",
    "Este é um processo que ajuda a melhorar a robustez e a precisão de um modelo final, combinando os resultados de várias árvores treinadas em diferentes amostras do dataset original, e a Random forest funciona melhor que o Bagging, pois as árvores amostradas são mais independentes (menor correlação), há mais vantagens utilizando a \"Sabedora das multidões\" e é bastante robusto a overtfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3). Implemente em python o código do bagging:\n",
    "    - Bootstrap\n",
    "    - Modelagem\n",
    "    - Agregação\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Coluna1 Coluna2  Coluna3  Coluna4  Coluna5  Coluna6 Coluna7  Coluna8  \\\n",
      "0        1       A     10.5     True      100      0.1       X      500   \n",
      "1        2       B     23.6    False      200      0.2       Y      600   \n",
      "2        3       C     35.7     True      300      0.3       Z      700   \n",
      "3        4       D     47.8    False      400      0.4       W      800   \n",
      "\n",
      "   Coluna9  \n",
      "0      1.1  \n",
      "1      2.2  \n",
      "2      3.3  \n",
      "3      4.4  \n"
     ]
    }
   ],
   "source": [
    "# Definindo os dados\n",
    "dados = {\n",
    "    'Coluna1': [1, 2, 3, 4],\n",
    "    'Coluna2': ['A', 'B', 'C', 'D'],\n",
    "    'Coluna3': [10.5, 23.6, 35.7, 47.8],\n",
    "    'Coluna4': [True, False, True, False],\n",
    "    'Coluna5': [100, 200, 300, 400],\n",
    "    'Coluna6': [0.1, 0.2, 0.3, 0.4],\n",
    "    'Coluna7': ['X', 'Y', 'Z', 'W'],\n",
    "    'Coluna8': [500, 600, 700, 800],\n",
    "    'Coluna9': [1.1, 2.2, 3.3, 4.4]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(dados)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Após Label Encoding:\n",
      "   Coluna1  Coluna2  Coluna3  Coluna4  Coluna5  Coluna6  Coluna7  Coluna8  \\\n",
      "0        1        0     10.5        1      100      0.1        1      500   \n",
      "1        2        1     23.6        0      200      0.2        2      600   \n",
      "2        3        2     35.7        1      300      0.3        3      700   \n",
      "3        4        3     47.8        0      400      0.4        0      800   \n",
      "\n",
      "   Coluna9  \n",
      "0      1.1  \n",
      "1      2.2  \n",
      "2      3.3  \n",
      "3      4.4  \n",
      "\n",
      "Distribuição das Classes:\n",
      "Coluna1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Accuracy: 0.00\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       0.0\n",
      "           2       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00       1.0\n",
      "   macro avg       0.00      0.00      0.00       1.0\n",
      "weighted avg       0.00      0.00      0.00       1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pré-processamento dos dados\n",
    "label_encoders = {}\n",
    "for col in ['Coluna2', 'Coluna4', 'Coluna7']:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "print(\"\\nDataset Após Label Encoding:\")\n",
    "print(df)\n",
    "\n",
    "# Separando features e target\n",
    "X = df.drop('Coluna1', axis=1)\n",
    "y = df['Coluna1']\n",
    "\n",
    "# Verificando a distribuição das classes no target\n",
    "print(\"\\nDistribuição das Classes:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# Dividindo o dataset em conjunto de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Treinando o modelo Random Forest\n",
    "random_forest = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Fazendo previsões e avaliando o modelo\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Avaliando a precisão com zero_division ajustado\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, zero_division=0)\n",
    "\n",
    "print(f'\\nAccuracy: {accuracy:.2f}')\n",
    "print('Classification Report:')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Observações\n",
    "\n",
    "- **Pequeno Tamanho do Dataset**: O dataset é pequeno para simplificar o exemplo, mas em aplicações reais, recomenda-se usar um conjunto de dados maior.\n",
    "- **Diversidade nas Amostras de Bootstrap**: A diversidade nas amostras geradas pelo bootstrap ajuda a criar um modelo mais robusto, minimizando o overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Índice",
   "title_sidebar": "Conteúdo",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
